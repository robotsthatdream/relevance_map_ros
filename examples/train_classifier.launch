<launch>
    <!-- Topics of the camera streams 
         An example for the Kinect2 camera used with kinect2_bridge.
    -->
    <rosparam ns="global">
            rgb_topic: "/kinect2/hd/image_color"
            depth_topic: "/kinect2/hd/image_depth_rect"
            rgb_info_topic: "/kinect2/hd/camera_info"
            depth_info_topic: "/kinect2/hd/camera_info"
            background: "/link/to/pcd/file"  <!-- the pcd file containing the background -->
    </rosparam>
    

    <!-- To launch the node example_node -->
    <node name="train_classifier" pkg="relevance_map" type="train_classifier" output="screen" launch-prefix="">
       <!-- gdb -\-args   -->
        <!-- The parameters for the workspace
             This parameters define a area in which the relevance map will be computed
        -->
        <rosparam ns="experiment/workspace">
            sphere:
                x: 0.
                y: 0.
                z: 1.
                radius: 10.
                threshold: 0.35
            csg_intersect_cuboid:
                x_min: -0.1
                x_max: 0.4
                y_min: -0.2
                y_max: 0.4
                z_min: -0.5
                z_max: 1.4
        </rosparam>

        <!-- Parameters specific to the classifier -->
        <rosparam ns="experiment/soi" subst_value="True">
            method: "gmm" <!-- the type of classifier. Here Gaussian Mixture Models-->
            mode: "exploration" <!-- how to use the classifier : exploration for training the classifier, exploitation for using the classifier. Warning : exploitation not implemented-->
            load_exp: ""  <!-- the folder where to find the archive of the classifier to load, or empty string to create a new classifier -->
            modality: "centralFPFHLabHist" <!-- the type of visual feature extracted on a supervoxel. For more info see the documentaion of the image processing library -->
            dimension: "48" <!-- The dimensionality of the visual feature -->
            threshold: "0.5" <!-- the threshold to binarize the relevance map -->
            alpha : "0.6" <!-- hyperparameter of the classifier. Only for training and only for the gmm classifier -->
        </rosparam>
        <rosparam ns="modalities/modality_1">
           name: "centralFPFHLabHist"
           dimension: 48
        </rosparam>
    </node>
</launch>

<!-- The parameters modality and dimension correspond to the visual features used for the training of the classifier and the computation of the relevance map. Three visual features are available : 
    - centralFPFH : FPFH is a common descriptor that characterizes shape based on a pointcloud of normals (Rusu et al. [2009]). In this implementation, FPFH is extracted on the central point of the pointcloud including the targeted supervoxel and its neighbors. The radius of neighborhood to compute FPFH is set to the size of a supervoxel, thus the central point FPFH takes into account the whole considered pointcloud. The central point is the centroid of the targeted supervoxel. The dimensionality is 33.
    - colorLabHist : Color histogram of a supervoxel extracted on CIELab color encoding. One histogram of 5 bins is computed separately on each dimension (L ∗ a ∗ b) and then they are concatenated. This feature space has 15 dimensions.
    - centralFPFHLabHist : The concatenation of colorLabHist and centralFPFH which has 48 dimensions.
-->
